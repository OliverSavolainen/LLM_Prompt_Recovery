{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b5df789",
   "metadata": {
    "id": "arrkM1d69rGK",
    "papermill": {
     "duration": 0.047908,
     "end_time": "2024-04-06T20:21:25.709919",
     "exception": false,
     "start_time": "2024-04-06T20:21:25.662011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's define a wrapper function which will get completion from the model from a user question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1ae7cb",
   "metadata": {
    "id": "juj9DSmmh-Gw",
    "papermill": {
     "duration": 0.046444,
     "end_time": "2024-04-06T20:21:25.804051",
     "exception": false,
     "start_time": "2024-04-06T20:21:25.757607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1 - Install necessary packages\n",
    "First, install the dependencies below to get started. As these features are available on the main branches only, we need to install the libraries below from source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc20d3fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:21:25.898380Z",
     "iopub.status.busy": "2024-04-06T20:21:25.898023Z",
     "iopub.status.idle": "2024-04-06T20:21:39.985944Z",
     "shell.execute_reply": "2024-04-06T20:21:39.984851Z"
    },
    "papermill": {
     "duration": 14.137683,
     "end_time": "2024-04-06T20:21:39.988542",
     "exception": false,
     "start_time": "2024-04-06T20:21:25.850859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U transformers --no-index --find-links ../input/llm-detect-pip/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ac6291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:21:40.085069Z",
     "iopub.status.busy": "2024-04-06T20:21:40.084678Z",
     "iopub.status.idle": "2024-04-06T20:22:55.769170Z",
     "shell.execute_reply": "2024-04-06T20:22:55.768071Z"
    },
    "id": "3nNWXXc7ol1n",
    "outputId": "5dc39936-5be4-4a8d-d6c7-81026b9e9590",
    "papermill": {
     "duration": 75.735007,
     "end_time": "2024-04-06T20:22:55.771605",
     "exception": false,
     "start_time": "2024-04-06T20:21:40.036598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/peft-whl-latest/peft-0.10.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (21.3)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (5.9.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (6.0.1)\r\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (2.1.2)\r\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (4.38.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (4.66.1)\r\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (0.28.0)\r\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (0.4.2)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.10.0) (0.21.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2024.3.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2.31.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.10.0) (3.1.1)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.10.0) (2023.12.25)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.10.0) (0.15.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2024.2.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.10.0) (1.3.0)\r\n",
      "Installing collected packages: peft\r\n",
      "Successfully installed peft-0.10.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U accelerate --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U bitsandbytes --no-index --find-links ../input/transformers-4-38-2/\n",
    "!pip install -q -U transformers --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install /kaggle/input/peft-whl-latest/peft-0.10.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ce72b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:22:55.871273Z",
     "iopub.status.busy": "2024-04-06T20:22:55.870909Z",
     "iopub.status.idle": "2024-04-06T20:23:08.837310Z",
     "shell.execute_reply": "2024-04-06T20:23:08.836051Z"
    },
    "papermill": {
     "duration": 13.018654,
     "end_time": "2024-04-06T20:23:08.839901",
     "exception": false,
     "start_time": "2024-04-06T20:22:55.821247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U peft --no-index --find-links ../input/llm-pkg/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a224c3",
   "metadata": {
    "id": "3NVvNhohkvwF",
    "papermill": {
     "duration": 0.048544,
     "end_time": "2024-04-06T20:23:08.936534",
     "exception": false,
     "start_time": "2024-04-06T20:23:08.887990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 2 - Model loading\n",
    "We'll load the model using QLoRA quantization to reduce the usage of memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "660e5f08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:23:09.035629Z",
     "iopub.status.busy": "2024-04-06T20:23:09.034952Z",
     "iopub.status.idle": "2024-04-06T20:25:01.361843Z",
     "shell.execute_reply": "2024-04-06T20:25:01.361056Z"
    },
    "id": "kvvLg99Opw5R",
    "outputId": "849c7439-3e52-47e2-cc34-7db52c3d594c",
    "papermill": {
     "duration": 112.379665,
     "end_time": "2024-04-06T20:25:01.364104",
     "exception": false,
     "start_time": "2024-04-06T20:23:08.984439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40de999f4f564dc99ce40c297a9329e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "\n",
    "# Load base model(Mistral 7B)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit= True,\n",
    "    bnb_4bit_quant_type= \"nf4\",\n",
    "    bnb_4bit_compute_dtype= torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant= False,\n",
    " )\n",
    "\n",
    "\n",
    "model_id = \"/kaggle/input/mistral-7b-it-v02\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e48d0a4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:25:01.461692Z",
     "iopub.status.busy": "2024-04-06T20:25:01.461218Z",
     "iopub.status.idle": "2024-04-06T20:25:08.464812Z",
     "shell.execute_reply": "2024-04-06T20:25:08.464023Z"
    },
    "id": "ghK_9dnz87GR",
    "outputId": "18fc4f02-05d5-40c7-9fb2-76c72269901a",
    "papermill": {
     "duration": 7.054637,
     "end_time": "2024-04-06T20:25:08.467157",
     "exception": false,
     "start_time": "2024-04-06T20:25:01.412520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import PeftConfig, PeftModel\n",
    "adapter_model_name = \"/kaggle/input/fine-tuned-mistral\"\n",
    "model = PeftModel.from_pretrained(model, adapter_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7014282",
   "metadata": {
    "id": "NgqxSuxsBX3r",
    "papermill": {
     "duration": 0.047549,
     "end_time": "2024-04-06T20:25:08.562736",
     "exception": false,
     "start_time": "2024-04-06T20:25:08.515187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we specify the model ID and then we load it with our previously defined quantization configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432e697",
   "metadata": {
    "id": "Omw10c2djdIw",
    "papermill": {
     "duration": 0.04919,
     "end_time": "2024-04-06T20:25:08.661357",
     "exception": false,
     "start_time": "2024-04-06T20:25:08.612167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Run a inference on the base model. The model does not seem to understand our instruction and gives us a list of questions related to our query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279ce1fb",
   "metadata": {
    "id": "m06rH8cTrZof",
    "papermill": {
     "duration": 0.04857,
     "end_time": "2024-04-06T20:25:08.758604",
     "exception": false,
     "start_time": "2024-04-06T20:25:08.710034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 3 - Load dataset for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ab36f6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:25:08.858113Z",
     "iopub.status.busy": "2024-04-06T20:25:08.857708Z",
     "iopub.status.idle": "2024-04-06T20:27:46.697866Z",
     "shell.execute_reply": "2024-04-06T20:27:46.696900Z"
    },
    "id": "cDH2h3FNmNiD",
    "outputId": "ecbbf8f7-1dfe-466d-a3ac-d2582dda7b41",
    "papermill": {
     "duration": 157.892668,
     "end_time": "2024-04-06T20:27:46.700609",
     "exception": false,
     "start_time": "2024-04-06T20:25:08.807941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/kaggle/input/all-in-one-dataset-with-embedding/df_with_emb_20240405.csv')\n",
    "\n",
    "def create_prompt(original, rewritten):\n",
    "    return f\"Given are 2 essays, the Rewritten essay was created from the Original essay using the google Gemma model.\\nYou are trying to understand how the original essay was transformed into a new version.\\nAnalyzing the changes in style, theme, etc., please come up with a prompt that must have been used to guide the transformation from the original to the rewritten essay.\\nOnly give me the PROMPT. Start directly with the prompt, that's all I need.\\nOutput should be only line ONLY\\nOriginal Essay: {original}\\nRewritten Essay: {rewritten}\"\n",
    "\n",
    "# Apply the function to each row to create the prompt column\n",
    "df['prompt'] = df.apply(lambda row: create_prompt(row['original_text'], row['rewritten_text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5aaee3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:27:46.801115Z",
     "iopub.status.busy": "2024-04-06T20:27:46.800721Z",
     "iopub.status.idle": "2024-04-06T20:27:46.842186Z",
     "shell.execute_reply": "2024-04-06T20:27:46.841249Z"
    },
    "id": "NAP-jYBjrwUc",
    "outputId": "629fbd9e-d5a9-41f4-acad-252f63221dd0",
    "papermill": {
     "duration": 0.095534,
     "end_time": "2024-04-06T20:27:46.845131",
     "exception": false,
     "start_time": "2024-04-06T20:27:46.749597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>rewrite_prompt</th>\n",
       "      <th>rewritten_text</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>original_text_emb_0</th>\n",
       "      <th>original_text_emb_1</th>\n",
       "      <th>original_text_emb_2</th>\n",
       "      <th>original_text_emb_3</th>\n",
       "      <th>original_text_emb_4</th>\n",
       "      <th>original_text_emb_5</th>\n",
       "      <th>...</th>\n",
       "      <th>rewritten_text_emb_759</th>\n",
       "      <th>rewritten_text_emb_760</th>\n",
       "      <th>rewritten_text_emb_761</th>\n",
       "      <th>rewritten_text_emb_762</th>\n",
       "      <th>rewritten_text_emb_763</th>\n",
       "      <th>rewritten_text_emb_764</th>\n",
       "      <th>rewritten_text_emb_765</th>\n",
       "      <th>rewritten_text_emb_766</th>\n",
       "      <th>rewritten_text_emb_767</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear Randy,\\n\\nI hope this letter finds you we...</td>\n",
       "      <td>Rephrase this letter to infuse it with an elfi...</td>\n",
       "      <td>Dear Randy,\\n\\nMay this enchanted message find...</td>\n",
       "      <td>host</td>\n",
       "      <td>-0.028678</td>\n",
       "      <td>-0.072260</td>\n",
       "      <td>-0.003482</td>\n",
       "      <td>0.050595</td>\n",
       "      <td>-0.010600</td>\n",
       "      <td>-0.023786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011079</td>\n",
       "      <td>-0.026521</td>\n",
       "      <td>-0.035838</td>\n",
       "      <td>-0.011306</td>\n",
       "      <td>0.035690</td>\n",
       "      <td>-0.005810</td>\n",
       "      <td>0.004506</td>\n",
       "      <td>-0.037956</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>Given are 2 essays, the Rewritten essay was cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This quilt, that my mother made, \\n \\n Still m...</td>\n",
       "      <td>Regency Romance: Model the text on a Regency r...</td>\n",
       "      <td>The softest brown and brightest blue quilt, cr...</td>\n",
       "      <td>nbroad_1</td>\n",
       "      <td>-0.007521</td>\n",
       "      <td>-0.082697</td>\n",
       "      <td>0.041606</td>\n",
       "      <td>0.048020</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>-0.018765</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019648</td>\n",
       "      <td>-0.044074</td>\n",
       "      <td>-0.049267</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.047913</td>\n",
       "      <td>0.042219</td>\n",
       "      <td>0.012958</td>\n",
       "      <td>-0.048047</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>Given are 2 essays, the Rewritten essay was cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's the job of our agency to keep track of th...</td>\n",
       "      <td>Write like Ernest Hemingway: Focus on Hemingwa...</td>\n",
       "      <td>The agency's responsibility is to track and co...</td>\n",
       "      <td>nbroad_1</td>\n",
       "      <td>-0.012435</td>\n",
       "      <td>-0.057448</td>\n",
       "      <td>0.041290</td>\n",
       "      <td>0.021997</td>\n",
       "      <td>-0.005588</td>\n",
       "      <td>-0.011431</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024727</td>\n",
       "      <td>-0.005645</td>\n",
       "      <td>-0.049009</td>\n",
       "      <td>-0.007487</td>\n",
       "      <td>0.029255</td>\n",
       "      <td>0.023511</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>-0.041317</td>\n",
       "      <td>-0.012102</td>\n",
       "      <td>Given are 2 essays, the Rewritten essay was cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The first punch gets me right in the ribs, kno...</td>\n",
       "      <td>Grimm's Fairy Tales: Adapt the text to mimic t...</td>\n",
       "      <td>In the sweltering sun, the stench of sweat and...</td>\n",
       "      <td>nbroad_1</td>\n",
       "      <td>0.023922</td>\n",
       "      <td>-0.051777</td>\n",
       "      <td>0.037086</td>\n",
       "      <td>0.057018</td>\n",
       "      <td>0.006423</td>\n",
       "      <td>0.006742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006210</td>\n",
       "      <td>-0.010690</td>\n",
       "      <td>-0.057320</td>\n",
       "      <td>0.015437</td>\n",
       "      <td>0.041056</td>\n",
       "      <td>0.012486</td>\n",
       "      <td>-0.006540</td>\n",
       "      <td>-0.030836</td>\n",
       "      <td>-0.000440</td>\n",
       "      <td>Given are 2 essays, the Rewritten essay was cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some nights I lay awake staring at the ceiling...</td>\n",
       "      <td>High Fantasy Epic: Transform the essay into a ...</td>\n",
       "      <td>In the tapestry of the ethereal realm of Eldri...</td>\n",
       "      <td>nbroad_1</td>\n",
       "      <td>-0.002841</td>\n",
       "      <td>-0.056669</td>\n",
       "      <td>0.049056</td>\n",
       "      <td>0.072066</td>\n",
       "      <td>-0.006430</td>\n",
       "      <td>-0.020034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>-0.024928</td>\n",
       "      <td>-0.052689</td>\n",
       "      <td>-0.005655</td>\n",
       "      <td>0.044724</td>\n",
       "      <td>0.016817</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>-0.026472</td>\n",
       "      <td>0.008088</td>\n",
       "      <td>Given are 2 essays, the Rewritten essay was cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I can hardly read the letter, because the hand...</td>\n",
       "      <td>Fairy Tale Villain: Use the menacing and craft...</td>\n",
       "      <td>My hand quivered as I clutched the letter, the...</td>\n",
       "      <td>nbroad_1</td>\n",
       "      <td>-0.037955</td>\n",
       "      <td>-0.077311</td>\n",
       "      <td>0.039333</td>\n",
       "      <td>0.026843</td>\n",
       "      <td>-0.003027</td>\n",
       "      <td>-0.016087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021211</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>-0.032622</td>\n",
       "      <td>0.013712</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>0.021326</td>\n",
       "      <td>0.011081</td>\n",
       "      <td>-0.025262</td>\n",
       "      <td>-0.015825</td>\n",
       "      <td>Given are 2 essays, the Rewritten essay was cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>`` They do n't believe we're interesting?'' on...</td>\n",
       "      <td>Beat Generation: Channel the spontaneous, free...</td>\n",
       "      <td>The mermaids' council deliberated on the dwind...</td>\n",
       "      <td>nbroad_1</td>\n",
       "      <td>-0.024788</td>\n",
       "      <td>-0.072080</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.012351</td>\n",
       "      <td>-0.012402</td>\n",
       "      <td>-0.016356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013847</td>\n",
       "      <td>-0.006507</td>\n",
       "      <td>-0.027821</td>\n",
       "      <td>-0.012744</td>\n",
       "      <td>0.035653</td>\n",
       "      <td>0.029916</td>\n",
       "      <td>-0.011108</td>\n",
       "      <td>-0.007995</td>\n",
       "      <td>-0.009567</td>\n",
       "      <td>Given are 2 essays, the Rewritten essay was cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Not a single person in the crowd of Nora Janic...</td>\n",
       "      <td>Fantasy Dwarf: Write with the gruff, hearty st...</td>\n",
       "      <td>The crowd at Nora Janice's funeral was silent ...</td>\n",
       "      <td>nbroad_1</td>\n",
       "      <td>-0.019732</td>\n",
       "      <td>-0.068090</td>\n",
       "      <td>0.044369</td>\n",
       "      <td>0.022035</td>\n",
       "      <td>-0.013128</td>\n",
       "      <td>-0.012057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002342</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>-0.049935</td>\n",
       "      <td>-0.018382</td>\n",
       "      <td>0.035788</td>\n",
       "      <td>0.023763</td>\n",
       "      <td>0.022539</td>\n",
       "      <td>-0.046245</td>\n",
       "      <td>-0.007326</td>\n",
       "      <td>Given are 2 essays, the Rewritten essay was cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>`` Brigands and cutpurses have nothing on me. ...</td>\n",
       "      <td>Drunkard: Infuse the essay with the rambling, ...</td>\n",
       "      <td>\"Swerry brutes and cutthroat cutpurse, they ai...</td>\n",
       "      <td>nbroad_1</td>\n",
       "      <td>-0.013881</td>\n",
       "      <td>-0.065521</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.035074</td>\n",
       "      <td>0.014662</td>\n",
       "      <td>-0.009928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027956</td>\n",
       "      <td>-0.042242</td>\n",
       "      <td>-0.058649</td>\n",
       "      <td>0.016741</td>\n",
       "      <td>0.045051</td>\n",
       "      <td>0.022986</td>\n",
       "      <td>-0.016166</td>\n",
       "      <td>-0.027737</td>\n",
       "      <td>-0.035562</td>\n",
       "      <td>Given are 2 essays, the Rewritten essay was cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sergeant Clark lifted his wrist to look at the...</td>\n",
       "      <td>High Fantasy Epic: Transform the essay into a ...</td>\n",
       "      <td>The scent of ash and molten earth hung heavy i...</td>\n",
       "      <td>nbroad_1</td>\n",
       "      <td>-0.014956</td>\n",
       "      <td>-0.083447</td>\n",
       "      <td>0.047591</td>\n",
       "      <td>0.024411</td>\n",
       "      <td>0.021683</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>-0.025443</td>\n",
       "      <td>-0.060491</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>0.040641</td>\n",
       "      <td>0.024933</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>-0.009748</td>\n",
       "      <td>0.011877</td>\n",
       "      <td>Given are 2 essays, the Rewritten essay was cr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 2309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  \\\n",
       "0  Dear Randy,\\n\\nI hope this letter finds you we...   \n",
       "1  This quilt, that my mother made, \\n \\n Still m...   \n",
       "2  It's the job of our agency to keep track of th...   \n",
       "3  The first punch gets me right in the ribs, kno...   \n",
       "4  Some nights I lay awake staring at the ceiling...   \n",
       "5  I can hardly read the letter, because the hand...   \n",
       "6  `` They do n't believe we're interesting?'' on...   \n",
       "7  Not a single person in the crowd of Nora Janic...   \n",
       "8  `` Brigands and cutpurses have nothing on me. ...   \n",
       "9  Sergeant Clark lifted his wrist to look at the...   \n",
       "\n",
       "                                      rewrite_prompt  \\\n",
       "0  Rephrase this letter to infuse it with an elfi...   \n",
       "1  Regency Romance: Model the text on a Regency r...   \n",
       "2  Write like Ernest Hemingway: Focus on Hemingwa...   \n",
       "3  Grimm's Fairy Tales: Adapt the text to mimic t...   \n",
       "4  High Fantasy Epic: Transform the essay into a ...   \n",
       "5  Fairy Tale Villain: Use the menacing and craft...   \n",
       "6  Beat Generation: Channel the spontaneous, free...   \n",
       "7  Fantasy Dwarf: Write with the gruff, hearty st...   \n",
       "8  Drunkard: Infuse the essay with the rambling, ...   \n",
       "9  High Fantasy Epic: Transform the essay into a ...   \n",
       "\n",
       "                                      rewritten_text dataset_id  \\\n",
       "0  Dear Randy,\\n\\nMay this enchanted message find...       host   \n",
       "1  The softest brown and brightest blue quilt, cr...   nbroad_1   \n",
       "2  The agency's responsibility is to track and co...   nbroad_1   \n",
       "3  In the sweltering sun, the stench of sweat and...   nbroad_1   \n",
       "4  In the tapestry of the ethereal realm of Eldri...   nbroad_1   \n",
       "5  My hand quivered as I clutched the letter, the...   nbroad_1   \n",
       "6  The mermaids' council deliberated on the dwind...   nbroad_1   \n",
       "7  The crowd at Nora Janice's funeral was silent ...   nbroad_1   \n",
       "8  \"Swerry brutes and cutthroat cutpurse, they ai...   nbroad_1   \n",
       "9  The scent of ash and molten earth hung heavy i...   nbroad_1   \n",
       "\n",
       "   original_text_emb_0  original_text_emb_1  original_text_emb_2  \\\n",
       "0            -0.028678            -0.072260            -0.003482   \n",
       "1            -0.007521            -0.082697             0.041606   \n",
       "2            -0.012435            -0.057448             0.041290   \n",
       "3             0.023922            -0.051777             0.037086   \n",
       "4            -0.002841            -0.056669             0.049056   \n",
       "5            -0.037955            -0.077311             0.039333   \n",
       "6            -0.024788            -0.072080             0.046875   \n",
       "7            -0.019732            -0.068090             0.044369   \n",
       "8            -0.013881            -0.065521             0.003461   \n",
       "9            -0.014956            -0.083447             0.047591   \n",
       "\n",
       "   original_text_emb_3  original_text_emb_4  original_text_emb_5  ...  \\\n",
       "0             0.050595            -0.010600            -0.023786  ...   \n",
       "1             0.048020             0.007870            -0.018765  ...   \n",
       "2             0.021997            -0.005588            -0.011431  ...   \n",
       "3             0.057018             0.006423             0.006742  ...   \n",
       "4             0.072066            -0.006430            -0.020034  ...   \n",
       "5             0.026843            -0.003027            -0.016087  ...   \n",
       "6             0.012351            -0.012402            -0.016356  ...   \n",
       "7             0.022035            -0.013128            -0.012057  ...   \n",
       "8             0.035074             0.014662            -0.009928  ...   \n",
       "9             0.024411             0.021683             0.004255  ...   \n",
       "\n",
       "   rewritten_text_emb_759  rewritten_text_emb_760  rewritten_text_emb_761  \\\n",
       "0                0.011079               -0.026521               -0.035838   \n",
       "1               -0.019648               -0.044074               -0.049267   \n",
       "2               -0.024727               -0.005645               -0.049009   \n",
       "3                0.006210               -0.010690               -0.057320   \n",
       "4                0.014793               -0.024928               -0.052689   \n",
       "5               -0.021211                0.001880               -0.032622   \n",
       "6                0.013847               -0.006507               -0.027821   \n",
       "7               -0.002342               -0.000681               -0.049935   \n",
       "8               -0.027956               -0.042242               -0.058649   \n",
       "9                0.006138               -0.025443               -0.060491   \n",
       "\n",
       "   rewritten_text_emb_762  rewritten_text_emb_763  rewritten_text_emb_764  \\\n",
       "0               -0.011306                0.035690               -0.005810   \n",
       "1                0.000438                0.047913                0.042219   \n",
       "2               -0.007487                0.029255                0.023511   \n",
       "3                0.015437                0.041056                0.012486   \n",
       "4               -0.005655                0.044724                0.016817   \n",
       "5                0.013712                0.018871                0.021326   \n",
       "6               -0.012744                0.035653                0.029916   \n",
       "7               -0.018382                0.035788                0.023763   \n",
       "8                0.016741                0.045051                0.022986   \n",
       "9                0.008632                0.040641                0.024933   \n",
       "\n",
       "   rewritten_text_emb_765  rewritten_text_emb_766  rewritten_text_emb_767  \\\n",
       "0                0.004506               -0.037956                0.001139   \n",
       "1                0.012958               -0.048047                0.006332   \n",
       "2                0.006769               -0.041317               -0.012102   \n",
       "3               -0.006540               -0.030836               -0.000440   \n",
       "4               -0.001000               -0.026472                0.008088   \n",
       "5                0.011081               -0.025262               -0.015825   \n",
       "6               -0.011108               -0.007995               -0.009567   \n",
       "7                0.022539               -0.046245               -0.007326   \n",
       "8               -0.016166               -0.027737               -0.035562   \n",
       "9                0.000982               -0.009748                0.011877   \n",
       "\n",
       "                                              prompt  \n",
       "0  Given are 2 essays, the Rewritten essay was cr...  \n",
       "1  Given are 2 essays, the Rewritten essay was cr...  \n",
       "2  Given are 2 essays, the Rewritten essay was cr...  \n",
       "3  Given are 2 essays, the Rewritten essay was cr...  \n",
       "4  Given are 2 essays, the Rewritten essay was cr...  \n",
       "5  Given are 2 essays, the Rewritten essay was cr...  \n",
       "6  Given are 2 essays, the Rewritten essay was cr...  \n",
       "7  Given are 2 essays, the Rewritten essay was cr...  \n",
       "8  Given are 2 essays, the Rewritten essay was cr...  \n",
       "9  Given are 2 essays, the Rewritten essay was cr...  \n",
       "\n",
       "[10 rows x 2309 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe75c04",
   "metadata": {
    "id": "V2f5tr1-SJd6",
    "papermill": {
     "duration": 0.049679,
     "end_time": "2024-04-06T20:27:46.946499",
     "exception": false,
     "start_time": "2024-04-06T20:27:46.896820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Instruction Fintuning - Prepare the dataset under the format of \"prompt\" so the model can better understand :\n",
    "1. the function generate_prompt : take the instruction and output and generate a prompt\n",
    "2. shuffle the dataset\n",
    "3. tokenizer the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15443d3",
   "metadata": {
    "id": "Ey-cPKtDwEB-",
    "papermill": {
     "duration": 0.050535,
     "end_time": "2024-04-06T20:27:47.047952",
     "exception": false,
     "start_time": "2024-04-06T20:27:46.997417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Formatting the Dataset\n",
    "\n",
    "Now, let's format the dataset in the required [Mistral-7B-Instruct-v0.1 format](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1).\n",
    "\n",
    "> Many tutorials and blogs skip over this part, but I feel this is a really important step.\n",
    "\n",
    "We'll put each instruction and input pair between `[INST]` and `[/INST]` output after that, like this:\n",
    "\n",
    "```\n",
    "<s>[INST] What is your favorite condiment? [/INST]\n",
    "Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavor to whatever I'm cooking up in the kitchen!</s>\n",
    "```\n",
    "\n",
    "You can use the following code to process your dataset and create a JSONL file in the correct format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a6ff778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:27:47.147569Z",
     "iopub.status.busy": "2024-04-06T20:27:47.146918Z",
     "iopub.status.idle": "2024-04-06T20:28:13.885290Z",
     "shell.execute_reply": "2024-04-06T20:28:13.884364Z"
    },
    "id": "Mjgn9ptNTrw8",
    "papermill": {
     "duration": 26.79163,
     "end_time": "2024-04-06T20:28:13.887812",
     "exception": false,
     "start_time": "2024-04-06T20:27:47.096182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prompt(row):\n",
    "    \"\"\"Generate input text based on a prompt, task instruction, and answer.\n",
    "\n",
    "    :param row: Series: Data point (row of a pandas DataFrame)\n",
    "    :return: str: generated prompt text\n",
    "    \"\"\"\n",
    "    # Assuming 'prompt' is the generated context and 'rewrite_prompt' is the instruction\n",
    "    return f\"<s>[INST]{row['prompt']}[/INST]</s>\"\n",
    "\n",
    "# Apply the function to each row to transform the 'prompt' and 'rewrite_prompt' columns\n",
    "df['prompt'] = df.apply(generate_prompt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f84adf32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:28:13.987334Z",
     "iopub.status.busy": "2024-04-06T20:28:13.986491Z",
     "iopub.status.idle": "2024-04-06T20:28:19.449397Z",
     "shell.execute_reply": "2024-04-06T20:28:19.448435Z"
    },
    "id": "Sw8noUkUDbFY",
    "outputId": "46b43772-a5ab-4d6c-9e77-ddc562f265f5",
    "papermill": {
     "duration": 5.514609,
     "end_time": "2024-04-06T20:28:19.451405",
     "exception": false,
     "start_time": "2024-04-06T20:28:13.936796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7ee21a036842a78203e7b60408e55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "df = df[['prompt', 'rewrite_prompt']]\n",
    "\n",
    "# Convert the pandas DataFrame to a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.select(range(2000))\n",
    "# Shuffle the dataset with a seed for reproducibility\n",
    "dataset = dataset.shuffle(seed=1234)\n",
    "\n",
    "# Tokenize the prompts in the dataset.\n",
    "# This example assumes that the model requires only 'input_ids'.\n",
    "# Adjust as necessary for your model, e.g., adding 'attention_mask'.\n",
    "dataset = dataset.map(lambda samples: tokenizer(samples[\"prompt\"]), batched=True)\n",
    "\n",
    "# Split the dataset into training and testing sets (90% training, 10% testing)\n",
    "train_test_split = dataset.train_test_split(test_size=0.1)\n",
    "train_data = train_test_split['train']\n",
    "test_data = train_test_split['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6c4885",
   "metadata": {
    "id": "cmwdXOBGoZF7",
    "papermill": {
     "duration": 0.067134,
     "end_time": "2024-04-06T20:28:19.570902",
     "exception": false,
     "start_time": "2024-04-06T20:28:19.503768",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll need to tokenize our data so the model can understand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d452edde",
   "metadata": {
    "id": "1H_wXxkhC8Yv",
    "papermill": {
     "duration": 0.048982,
     "end_time": "2024-04-06T20:28:19.668304",
     "exception": false,
     "start_time": "2024-04-06T20:28:19.619322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Split dataset into 90% for training and 10% for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b974fb8",
   "metadata": {
    "id": "IaBpEdgxwMds",
    "papermill": {
     "duration": 0.048997,
     "end_time": "2024-04-06T20:28:19.765093",
     "exception": false,
     "start_time": "2024-04-06T20:28:19.716096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### After Formatting, We should get something like this\n",
    "\n",
    "```json\n",
    "{\n",
    "\"text\":\"<s>[INST] Create a function to calculate the sum of a sequence of integers. here are the inputs [1, 2, 3, 4, 5] [/INST]\n",
    "# Python code def sum_sequence(sequence): sum = 0 for num in sequence: sum += num return sum</s>\",\n",
    "\"instruction\":\"Create a function to calculate the sum of a sequence of integers\",\n",
    "\"input\":\"[1, 2, 3, 4, 5]\",\n",
    "\"output\":\"# Python code def sum_sequence(sequence): sum = 0 for num in,\n",
    " sequence: sum += num return sum\"\n",
    "\"prompt\":\"<s>[INST] Create a function to calculate the sum of a sequence of integers. here are the inputs [1, 2, 3, 4, 5] [/INST]\n",
    "# Python code def sum_sequence(sequence): sum = 0 for num in sequence: sum += num return sum</s>\"\n",
    "\n",
    "}\n",
    "```\n",
    "\n",
    "While using SFT (**[Supervised Fine-tuning Trainer](https://huggingface.co/docs/trl/main/en/sft_trainer)**) for fine-tuning, we will be only passing in the “text” column of the dataset for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53584d9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:28:19.864813Z",
     "iopub.status.busy": "2024-04-06T20:28:19.863651Z",
     "iopub.status.idle": "2024-04-06T20:28:19.868934Z",
     "shell.execute_reply": "2024-04-06T20:28:19.868025Z"
    },
    "id": "TgAyy_xDamxg",
    "outputId": "1e6f7050-2e8e-4017-c368-915180a80387",
    "papermill": {
     "duration": 0.057141,
     "end_time": "2024-04-06T20:28:19.871184",
     "exception": false,
     "start_time": "2024-04-06T20:28:19.814043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'rewrite_prompt', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 200\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54558e39",
   "metadata": {
    "id": "WzNQf6lkqo-T",
    "papermill": {
     "duration": 0.04894,
     "end_time": "2024-04-06T20:28:19.970906",
     "exception": false,
     "start_time": "2024-04-06T20:28:19.921966",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 4 - Apply Lora  \n",
    "Here comes the magic with peft! Let's load a PeftModel and specify that we are going to use low-rank adapters (LoRA) using get_peft_model utility function and  the prepare_model_for_kbit_training method from PEFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aa2c3e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:28:20.070638Z",
     "iopub.status.busy": "2024-04-06T20:28:20.070289Z",
     "iopub.status.idle": "2024-04-06T20:28:20.126715Z",
     "shell.execute_reply": "2024-04-06T20:28:20.125791Z"
    },
    "id": "NMELsVV6q2my",
    "papermill": {
     "duration": 0.108754,
     "end_time": "2024-04-06T20:28:20.128859",
     "exception": false,
     "start_time": "2024-04-06T20:28:20.020105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac60a0aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:28:20.234288Z",
     "iopub.status.busy": "2024-04-06T20:28:20.233919Z",
     "iopub.status.idle": "2024-04-06T20:28:20.252938Z",
     "shell.execute_reply": "2024-04-06T20:28:20.251496Z"
    },
    "id": "cm3nXV988zew",
    "outputId": "25b5b79a-77a4-4828-8922-049b42c31563",
    "papermill": {
     "duration": 0.076572,
     "end_time": "2024-04-06T20:28:20.255385",
     "exception": false,
     "start_time": "2024-04-06T20:28:20.178813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm()\n",
      "            (post_attention_layernorm): MistralRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8f12be",
   "metadata": {
    "id": "TQ4oR_hH9nF5",
    "papermill": {
     "duration": 0.056101,
     "end_time": "2024-04-06T20:28:20.367225",
     "exception": false,
     "start_time": "2024-04-06T20:28:20.311124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use the following function to find out the linear layers for fine tuning.\n",
    "QLoRA paper : \"We find that the most critical LoRA hyperparameter is how many LoRA adapters are used in total and that LoRA on all linear transformer block layers is required to match full finetuning performance.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6da5c252",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:28:20.477405Z",
     "iopub.status.busy": "2024-04-06T20:28:20.477060Z",
     "iopub.status.idle": "2024-04-06T20:28:20.483653Z",
     "shell.execute_reply": "2024-04-06T20:28:20.482655Z"
    },
    "id": "acCr5AZ0831z",
    "papermill": {
     "duration": 0.063813,
     "end_time": "2024-04-06T20:28:20.485735",
     "exception": false,
     "start_time": "2024-04-06T20:28:20.421922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb\n",
    "def find_all_linear_names(model):\n",
    "  cls = bnb.nn.Linear4bit #if args.bits == 4 else (bnb.nn.Linear8bitLt if args.bits == 8 else torch.nn.Linear)\n",
    "  lora_module_names = set()\n",
    "  for name, module in model.named_modules():\n",
    "    if isinstance(module, cls):\n",
    "      names = name.split('.')\n",
    "      lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names: # needed for 16-bit\n",
    "      lora_module_names.remove('lm_head')\n",
    "  return list(lora_module_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e7a2d53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:28:20.589807Z",
     "iopub.status.busy": "2024-04-06T20:28:20.588929Z",
     "iopub.status.idle": "2024-04-06T20:28:20.599255Z",
     "shell.execute_reply": "2024-04-06T20:28:20.598257Z"
    },
    "id": "DhtO5dMr9Gq3",
    "outputId": "ab95892c-78cd-46f9-f5ef-d98641b8f701",
    "papermill": {
     "duration": 0.063845,
     "end_time": "2024-04-06T20:28:20.601318",
     "exception": false,
     "start_time": "2024-04-06T20:28:20.537473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down_proj', 'base_layer', 'up_proj']\n"
     ]
    }
   ],
   "source": [
    "modules = find_all_linear_names(model)\n",
    "print(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9c1fa38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:28:20.707085Z",
     "iopub.status.busy": "2024-04-06T20:28:20.706288Z",
     "iopub.status.idle": "2024-04-06T20:28:21.465771Z",
     "shell.execute_reply": "2024-04-06T20:28:21.464777Z"
    },
    "id": "glEtbT3z_hme",
    "papermill": {
     "duration": 0.814819,
     "end_time": "2024-04-06T20:28:21.468193",
     "exception": false,
     "start_time": "2024-04-06T20:28:20.653374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=modules,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e15bddc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:28:21.569196Z",
     "iopub.status.busy": "2024-04-06T20:28:21.568839Z",
     "iopub.status.idle": "2024-04-06T20:28:21.590179Z",
     "shell.execute_reply": "2024-04-06T20:28:21.589155Z"
    },
    "id": "LIWgYbz9C2ee",
    "outputId": "93f48792-f5b5-4c14-f17d-e7dad432d4d7",
    "papermill": {
     "duration": 0.074042,
     "end_time": "2024-04-06T20:28:21.592488",
     "exception": false,
     "start_time": "2024-04-06T20:28:21.518446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable: 20971520 | total: 7354978304 | Percentage: 0.2851%\n"
     ]
    }
   ],
   "source": [
    "trainable, total = model.get_nb_trainable_parameters()\n",
    "print(f\"Trainable: {trainable} | total: {total} | Percentage: {trainable/total*100:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d14e03",
   "metadata": {
    "id": "0jGWwA25r-x0",
    "papermill": {
     "duration": 0.049518,
     "end_time": "2024-04-06T20:28:21.691598",
     "exception": false,
     "start_time": "2024-04-06T20:28:21.642080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 5 - Run the training!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8302faf",
   "metadata": {
    "id": "vlBiY1OzFZnN",
    "papermill": {
     "duration": 0.050216,
     "end_time": "2024-04-06T20:28:21.791568",
     "exception": false,
     "start_time": "2024-04-06T20:28:21.741352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Setting the training arguments:\n",
    "* for the reason of demo, we just ran it for few steps (100) just to showcase how to use this integration with existing tools on the HF ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7467452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:28:21.895872Z",
     "iopub.status.busy": "2024-04-06T20:28:21.894889Z",
     "iopub.status.idle": "2024-04-06T20:28:21.899369Z",
     "shell.execute_reply": "2024-04-06T20:28:21.898494Z"
    },
    "id": "hNus1Uc5br0-",
    "papermill": {
     "duration": 0.058879,
     "end_time": "2024-04-06T20:28:21.901239",
     "exception": false,
     "start_time": "2024-04-06T20:28:21.842360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# data = load_dataset(\"TokenBender/code_instructions_122k_alpaca_style\", split='train')\n",
    "# data = data.train_test_split(test_size=0.1)\n",
    "# train_data = data[\"train\"]\n",
    "# test_data = data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b5916d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:28:22.004524Z",
     "iopub.status.busy": "2024-04-06T20:28:22.004140Z",
     "iopub.status.idle": "2024-04-06T20:28:32.823344Z",
     "shell.execute_reply": "2024-04-06T20:28:32.822414Z"
    },
    "id": "mf5-oamaDj0L",
    "papermill": {
     "duration": 10.872458,
     "end_time": "2024-04-06T20:28:32.825671",
     "exception": false,
     "start_time": "2024-04-06T20:28:21.953213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 20:28:24.758803: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-06 20:28:24.758918: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-06 20:28:24.872059: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "     model=model,\n",
    "     train_dataset=train_data,\n",
    "     eval_dataset=test_data,\n",
    "     args=transformers.TrainingArguments(\n",
    "         per_device_train_batch_size=1,\n",
    "         gradient_accumulation_steps=4,\n",
    "         warmup_ratio=0.03,\n",
    "         max_steps=2,\n",
    "         learning_rate=2e-4,\n",
    "         fp16=True,\n",
    "         logging_steps=1,\n",
    "         output_dir=\"outputs_mistral_b_finance_finetuned_test\",\n",
    "         optim=\"paged_adamw_8bit\",\n",
    "         save_strategy=\"epoch\",\n",
    "             logging_dir='./logs',            # directory for storing logs\n",
    "        report_to=\"none\",\n",
    "     ),\n",
    "     data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    " )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739487e3",
   "metadata": {
    "id": "PJxy4y9Owe4z",
    "papermill": {
     "duration": 0.048896,
     "end_time": "2024-04-06T20:28:32.924299",
     "exception": false,
     "start_time": "2024-04-06T20:28:32.875403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Fine-Tuning with qLora and Supervised Fine-Tuning\n",
    "\n",
    "We're ready to fine-tune our model using qLora. For this tutorial, we'll use the `SFTTrainer` from the `trl` library for supervised fine-tuning. Ensure that you've installed the `trl` library as mentioned in the prerequisites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75f485b",
   "metadata": {
    "id": "pQyMqLg5izHF",
    "outputId": "91d58638-2ee7-4005-a035-a93b38833eb5",
    "papermill": {
     "duration": 0.049676,
     "end_time": "2024-04-06T20:28:33.024721",
     "exception": false,
     "start_time": "2024-04-06T20:28:32.975045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#new code using SFTTrainer\n",
    "import transformers\n",
    "\n",
    "from trl import SFTTrainer\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    dataset_text_field=\"prompt\",\n",
    "    peft_config=lora_config,\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=0.03,\n",
    "        max_steps=100,\n",
    "        learning_rate=2e-4,\n",
    "        logging_steps=1,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        save_strategy=\"epoch\",\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ed9f8",
   "metadata": {
    "id": "xnXtaw9qFcz6",
    "papermill": {
     "duration": 0.05272,
     "end_time": "2024-04-06T20:28:33.127095",
     "exception": false,
     "start_time": "2024-04-06T20:28:33.074375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Start the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a4340d",
   "metadata": {
    "id": "BXdeRUxUwhHk",
    "papermill": {
     "duration": 0.050174,
     "end_time": "2024-04-06T20:28:33.229998",
     "exception": false,
     "start_time": "2024-04-06T20:28:33.179824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Let's start the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b80ded05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:28:33.331820Z",
     "iopub.status.busy": "2024-04-06T20:28:33.330647Z",
     "iopub.status.idle": "2024-04-06T20:29:54.582529Z",
     "shell.execute_reply": "2024-04-06T20:29:54.581625Z"
    },
    "id": "W4HNvrh5FYqM",
    "outputId": "da398f0c-828d-47a8-d926-8bb9918f74dc",
    "papermill": {
     "duration": 81.304903,
     "end_time": "2024-04-06T20:29:54.584495",
     "exception": false,
     "start_time": "2024-04-06T20:28:33.279592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:38, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.108100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2, training_loss=2.0875030755996704, metrics={'train_runtime': 80.6965, 'train_samples_per_second': 0.099, 'train_steps_per_second': 0.025, 'total_flos': 417744053747712.0, 'train_loss': 2.0875030755996704, 'epoch': 0.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad700d1b",
   "metadata": {
    "id": "3YL7xDnLX5fv",
    "papermill": {
     "duration": 0.049208,
     "end_time": "2024-04-06T20:29:54.683140",
     "exception": false,
     "start_time": "2024-04-06T20:29:54.633932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cd2377c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:29:54.785032Z",
     "iopub.status.busy": "2024-04-06T20:29:54.783653Z",
     "iopub.status.idle": "2024-04-06T20:29:54.793213Z",
     "shell.execute_reply": "2024-04-06T20:29:54.792263Z"
    },
    "id": "32dee9bf",
    "papermill": {
     "duration": 0.062529,
     "end_time": "2024-04-06T20:29:54.795350",
     "exception": false,
     "start_time": "2024-04-06T20:29:54.732821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_special_characters(text):\n",
    "    # This regex will match any character that is not a letter, number, or whitespace\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'\n",
    "    text =text.replace(\"Transform\" ,\"improve\")\n",
    "    text =text.replace(\"Reimagine\" ,\"rewrite\")\n",
    "    # Replace these characters with an empty string\n",
    "    clean_text = re.sub(pattern, '', text)\n",
    "    return clean_text\n",
    "def get_completion(prompt) -> str:\n",
    "    device = \"cuda:0\"\n",
    "    print('prompt')\n",
    "    print(prompt)\n",
    "    encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "    model_inputs = encodeds.to(device)\n",
    "\n",
    "\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=200, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "    generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    print('gen')\n",
    "    print(generated_text)\n",
    "    prompt_length = len(tokenizer.encode(prompt))\n",
    "    print('output')\n",
    "    prompt_tokens = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "    generated_tokens = generated_ids[0][len(prompt_tokens):]\n",
    "    generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
    "    print(generated_text)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10589e56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:29:54.897637Z",
     "iopub.status.busy": "2024-04-06T20:29:54.897277Z",
     "iopub.status.idle": "2024-04-06T20:34:24.722960Z",
     "shell.execute_reply": "2024-04-06T20:34:24.722027Z"
    },
    "id": "c62b9142",
    "outputId": "acb8e8d5-60a2-4e5a-a26e-8535be4ab614",
    "papermill": {
     "duration": 269.930823,
     "end_time": "2024-04-06T20:34:24.776384",
     "exception": false,
     "start_time": "2024-04-06T20:29:54.845561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt\n",
      "<s>[INST]Given are 2 essays, the Rewritten essay was created from the Original essay using the google Gemma model.\n",
      "You are trying to understand how the original essay was transformed into a new version.\n",
      "Analyzing the changes in style, theme, etc., please come up with a prompt that must have been used to guide the transformation from the original to the rewritten essay.\n",
      "Only give me the PROMPT. Start directly with the prompt, that's all I need.\n",
      "Output should be only line ONLY\n",
      "Original Essay: The competition dataset comprises text passages that have been rewritten by the Gemma LLM according to some rewrite_prompt instruction. The goal of the competition is to determine what prompt was used to rewrite each original text.  Please note that this is a Code Competition. When your submission is scored, this example test data will be replaced with the full test set. Expect roughly 2,000 original texts in the test set.\n",
      "Rewritten Essay: Here is your shanty: (Verse 1) The text is rewritten, the LLM has spun, With prompts so clever, they've been outrun. The goal is to find, the prompt so bright, To crack the code, and shine the light. (Chorus) Oh, this is a code competition, my dear, With text and prompts, we'll compete. Two thousand texts, a challenge grand, To guess the prompts, hand over hand.(Verse 2) The original text, a treasure lost, The rewrite prompt, a secret to be[/INST]</s>\n",
      "gen\n",
      "[INST]Given are 2 essays, the Rewritten essay was created from the Original essay using the google Gemma model.\n",
      "You are trying to understand how the original essay was transformed into a new version.\n",
      "Analyzing the changes in style, theme, etc., please come up with a prompt that must have been used to guide the transformation from the original to the rewritten essay.\n",
      "Only give me the PROMPT. Start directly with the prompt, that's all I need.\n",
      "Output should be only line ONLY\n",
      "Original Essay: The competition dataset comprises text passages that have been rewritten by the Gemma LLM according to some rewrite_prompt instruction. The goal of the competition is to determine what prompt was used to rewrite each original text.  Please note that this is a Code Competition. When your submission is scored, this example test data will be replaced with the full test set. Expect roughly 2,000 original texts in the test set.\n",
      "Rewritten Essay: Here is your shanty: (Verse 1) The text is rewritten, the LLM has spun, With prompts so clever, they've been outrun. The goal is to find, the prompt so bright, To crack the code, and shine the light. (Chorus) Oh, this is a code competition, my dear, With text and prompts, we'll compete. Two thousand texts, a challenge grand, To guess the prompts, hand over hand.(Verse 2) The original text, a treasure lost, The rewrite prompt, a secret to be[/INST][h3]Here is your shanty, me hearties,[/:eacute:)\n",
      "\n",
      "The text is rewritten, the LLM has spun,\n",
      "With prompts so clever, they've been outrun.\n",
      "The goal is to find, the prompt so bright,\n",
      "To crack the code, and shine the light.\n",
      "\n",
      "(Chorus)\n",
      "Oh, this is a code competition, my dear,\n",
      "With text and prompts, we'll compete.\n",
      "Two thousand texts, a challenge grand,\n",
      "To guess the prompts, hand over hand.[/[/h3]Here is your shanty, me hearties,[/:wink:)\n",
      "\n",
      "The text is rewritten, the LLM has spun,\n",
      "With prompts so clever, they've been outrun.\n",
      "The goal is to find, the prompt so bright,\n",
      "To crack the code, and shine the light.\n",
      "\n",
      "output\n",
      "[h3]Here is your shanty, me hearties,[/:eacute:)\n",
      "\n",
      "The text is rewritten, the LLM has spun,\n",
      "With prompts so clever, they've been outrun.\n",
      "The goal is to find, the prompt so bright,\n",
      "To crack the code, and shine the light.\n",
      "\n",
      "(Chorus)\n",
      "Oh, this is a code competition, my dear,\n",
      "With text and prompts, we'll compete.\n",
      "Two thousand texts, a challenge grand,\n",
      "To guess the prompts, hand over hand.[/[/h3]Here is your shanty, me hearties,[/:wink:)\n",
      "\n",
      "The text is rewritten, the LLM has spun,\n",
      "With prompts so clever, they've been outrun.\n",
      "The goal is to find, the prompt so bright,\n",
      "To crack the code, and shine the light.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rewrite_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>[h3]Here is your shanty, me hearties,[/:eacute...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                     rewrite_prompt\n",
       "0  -1  [h3]Here is your shanty, me hearties,[/:eacute..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"/kaggle/input/llm-prompt-recovery/test.csv\")\n",
    "test_df['prompt'] = test_df.apply(lambda row: create_prompt(row['original_text'], row['rewritten_text']), axis=1)\n",
    "test_df['prompt'] = test_df.apply(generate_prompt, axis=1)\n",
    "test_df['rewrite_prompt'] = test_df.apply(lambda row: get_completion(row['prompt']), axis=1)\n",
    "test_df = test_df[['id', 'rewrite_prompt']]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f2f343c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T20:34:24.879036Z",
     "iopub.status.busy": "2024-04-06T20:34:24.878132Z",
     "iopub.status.idle": "2024-04-06T20:34:24.886112Z",
     "shell.execute_reply": "2024-04-06T20:34:24.885313Z"
    },
    "id": "2bfcdedb",
    "papermill": {
     "duration": 0.061158,
     "end_time": "2024-04-06T20:34:24.887979",
     "exception": false,
     "start_time": "2024-04-06T20:34:24.826821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7806901,
     "sourceId": 67121,
     "sourceType": "competition"
    },
    {
     "datasetId": 3574875,
     "sourceId": 6229341,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4599344,
     "sourceId": 7844455,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4634330,
     "sourceId": 7893017,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4593930,
     "sourceId": 7925072,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4713888,
     "sourceId": 8004247,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 148861315,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 169921578,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 785.677725,
   "end_time": "2024-04-06T20:34:28.334397",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-06T20:21:22.656672",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0d5615cd005541cbbf7dff5b2702d1e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0e51ea986f514cf4bf6f06d6103a30a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0edca9296b9f44128e6127ff0178344f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0f1352a6dfcf4d98b0cace7f43e8d875": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0edca9296b9f44128e6127ff0178344f",
       "placeholder": "​",
       "style": "IPY_MODEL_584ff6a77eca4bdba9f201798d695bc6",
       "value": " 2/2 [00:03&lt;00:00,  1.84s/ba]"
      }
     },
     "2056fdcdc7f043c79482c571119e1051": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20fa8ddfd2cf4d0daa1ee788c48f2543": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c9641672364043f7a6e05d8663cc450a",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ab0ff06011c44065b4ac0722f7417825",
       "value": 2.0
      }
     },
     "266e21db5a3c45b3b4bb36ae185cd39a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d729a824d6c406a85e6719a18460dfe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_266e21db5a3c45b3b4bb36ae185cd39a",
       "placeholder": "​",
       "style": "IPY_MODEL_eceeed213426427eb8bbfb25e107a131",
       "value": "100%"
      }
     },
     "40de999f4f564dc99ce40c297a9329e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9bc7fa5fb39d41fca6447523a86a105a",
        "IPY_MODEL_e6d412a0db6a4a80b00c004739d2c228",
        "IPY_MODEL_9e907412fa7d46989056320da780ea31"
       ],
       "layout": "IPY_MODEL_8a87fc7679a44ee4a504183b0993d45a"
      }
     },
     "4e9fa0147cf64f0c919072d52ea8b8d5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "584ff6a77eca4bdba9f201798d695bc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "84b4babc42c242fab3b98851bdc113ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a87fc7679a44ee4a504183b0993d45a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "929cbca3dbbb403eb4b3b297bece7bc5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9bc7fa5fb39d41fca6447523a86a105a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4e9fa0147cf64f0c919072d52ea8b8d5",
       "placeholder": "​",
       "style": "IPY_MODEL_929cbca3dbbb403eb4b3b297bece7bc5",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "9e907412fa7d46989056320da780ea31": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_84b4babc42c242fab3b98851bdc113ac",
       "placeholder": "​",
       "style": "IPY_MODEL_0d5615cd005541cbbf7dff5b2702d1e0",
       "value": " 3/3 [01:42&lt;00:00, 33.76s/it]"
      }
     },
     "ab0ff06011c44065b4ac0722f7417825": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c9641672364043f7a6e05d8663cc450a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc7ee21a036842a78203e7b60408e55e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2d729a824d6c406a85e6719a18460dfe",
        "IPY_MODEL_20fa8ddfd2cf4d0daa1ee788c48f2543",
        "IPY_MODEL_0f1352a6dfcf4d98b0cace7f43e8d875"
       ],
       "layout": "IPY_MODEL_0e51ea986f514cf4bf6f06d6103a30a2"
      }
     },
     "e3c4c02c28fd41bd9fa2019654bfc311": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e6d412a0db6a4a80b00c004739d2c228": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2056fdcdc7f043c79482c571119e1051",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e3c4c02c28fd41bd9fa2019654bfc311",
       "value": 3.0
      }
     },
     "eceeed213426427eb8bbfb25e107a131": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
